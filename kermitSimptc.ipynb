{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Tesi magistrale\\KermitSimptc\n"
     ]
    }
   ],
   "source": [
    "import time, pickle, ast, os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#script for reading/writing trees\n",
    "from scripts.script import readP, writeTree\n",
    "#script for build DTK\n",
    "from scripts.script import createDTK\n",
    "#script for parse sentences\n",
    "from scripts.script import parse\n",
    "\n",
    "from os import getcwd\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(getcwd());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Download agnews\n",
    "# !wget wget https://data.deepai.org/agnews.zip\n",
    "#\n",
    "# !unzip agnews.zip\n",
    "\n",
    "data_train = pd.read_csv('./agnews/train.csv')\n",
    "data_train = data_train.sample(1000)\n",
    "dataset_name= \"agnews\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:14<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "name = 'dtk_trees_'+dataset_name+'.pkl'\n",
    "name2 = 'log_'+dataset_name+'.txt'\n",
    "name3 = 'dt_'+dataset_name+'.txt'\n",
    "\n",
    "i = 0\n",
    "cont = 0\n",
    "listTree = []\n",
    "newList = []\n",
    "oldList = []\n",
    "\n",
    "tree = \"(S)\"\n",
    "treeException = createDTK(tree)\n",
    "\n",
    "\n",
    "for line in tqdm(data_train['Description']):\n",
    "    cont += 1\n",
    "    try:\n",
    "        tree = (parse(line))\n",
    "        treeDTK = createDTK(tree)\n",
    "    except Exception:\n",
    "        tree, treeDTK = \"(S)\", treeException\n",
    "\n",
    "    listTree.append(treeDTK)\n",
    "    #write parenthetical tree\n",
    "    writeTree(name3,tree)\n",
    "    #every 5000 shafts saves the corresponding DTKs\n",
    "    if i>5000:\n",
    "        time.sleep(1)\n",
    "        if os.path.isfile(name):\n",
    "            #append new encoded tree in pickle file\n",
    "            oldList = readP(name)\n",
    "            newList = oldList+listTree\n",
    "        else:\n",
    "            newList = listTree\n",
    "\n",
    "        f=open(name, 'wb')\n",
    "\n",
    "        for x in newList:\n",
    "            pickle.dump(x, f)\n",
    "        f.close()\n",
    "\n",
    "        f=open(name2, \"a+\")\n",
    "        f.write(str(cont)+'..')\n",
    "        f.close()\n",
    "\n",
    "        i = 0\n",
    "        listTree = []\n",
    "        newList = []\n",
    "        oldList = []\n",
    "    else:\n",
    "        i +=1\n",
    "\n",
    "#checking consistency\n",
    "if os.path.isfile(name):\n",
    "    oldList = readP(name)\n",
    "    newList = oldList+listTree\n",
    "else:\n",
    "    newList = listTree\n",
    "f=open(name, 'wb')\n",
    "for x in newList:\n",
    "    pickle.dump(x, f)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "with open('dtk_trees_agnews.pkl', 'rb') as f:\n",
    "    unpickled = pickle.load(f)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from simptc import configs\n",
    "def encode_sentence(prompted_text):\n",
    "    try:\n",
    "        tree = (parse(prompted_text))\n",
    "        treeDTK = createDTK(tree)\n",
    "    except Exception:\n",
    "        tree, treeDTK = \"(S)\", treeException\n",
    "    return treeDTK\n",
    "\n",
    "def load_label_names(dataset):\n",
    "    label_name_file = f\"./agnews/label_names.txt\"\n",
    "    labels = []\n",
    "    with open(label_name_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            words = line.split(\"\\n\")[0].split(\",\")\n",
    "            labels.append(words)\n",
    "    return labels\n",
    "\n",
    "def encode_label_names(dataset, label_name_file, model, tokenizer, model_name):\n",
    "    print(\"encoding class anchor sentences...\")\n",
    "    embedding_dir = f'./agnews/embeddings'\n",
    "    if not os.path.exists(embedding_dir):\n",
    "        os.mkdir(embedding_dir)\n",
    "    simcse = False\n",
    "    labels = []\n",
    "    with open(label_name_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            words = line.split(\"\\n\")[0].split(\",\")\n",
    "            labels.append(words)\n",
    "\n",
    "    template_number = len(configs.TEMPLATES[\"agnews\"])\n",
    "    for template_id in range(template_number):\n",
    "        if simcse:\n",
    "            model_name_with_prefix = f\"simcse_{True}_\" + model_name\n",
    "        else:\n",
    "            model_name_with_prefix = model_name\n",
    "        if label_name_file.split('/')[-1] == 'label_names.txt':\n",
    "            prompt_path = os.path.join(embedding_dir, f\"prompt_{template_id}_{model_name_with_prefix}.npz\")\n",
    "        else:\n",
    "            label_names_name = label_name_file.split('/')[-1][12:-4]   # extract label names name\n",
    "            prompt_path = os.path.join(embedding_dir, f\"prompt_{template_id}_{label_names_name}_{model_name_with_prefix}.npz\")\n",
    "        template = configs.TEMPLATES[\"agnews\"][template_id]\n",
    "        # create prompt embeddings:\n",
    "        if not os.path.exists(prompt_path):\n",
    "            print(f\"generating prompt embeddings using {model_name} from {label_name_file}, template: {template}\")\n",
    "            print(f\"embedding path = {prompt_path}\")\n",
    "            label_list = []\n",
    "            prompt_embeddings = []\n",
    "            for label_id, label_words in enumerate(labels):\n",
    "                show_example = True\n",
    "                for label_word in label_words:\n",
    "                    prompted_text = template.replace(\"<mask>\", label_word)\n",
    "                    if show_example:\n",
    "                        show_example = False\n",
    "                        print(f\"prompt exampe: {prompted_text}\")\n",
    "                    prompt_embeddings.append(encode_sentence(prompted_text))\n",
    "                    label_list.append(label_id)\n",
    "            prompt_embeddings = np.array(prompt_embeddings)\n",
    "            label_list = np.array(label_list)\n",
    "            print(f\"embedding shape: {prompt_embeddings.shape}\")\n",
    "            np.savez(prompt_path, embedding_list=prompt_embeddings, label_list=label_list)\n",
    "        else:\n",
    "            print(f\"prompt embeddings already exists at {prompt_path}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def encode_and_save_sentences(dataset, suffix, model, tokenizer, model_name, split):\n",
    "    logger.info(\"encoding train and test set...\")\n",
    "    # label_path = os.path.join(f\"./datasets/TextClassification/{dataset}\", f\"{split}_labels.{suffix}\")\n",
    "    embedding_dir = os.path.join(f\"./agnews/dataset/\", \"embeddings\")\n",
    "\n",
    "    if not os.path.exists(embedding_dir):\n",
    "        os.mkdir(embedding_dir)\n",
    "    if model_name in [\"roberta_large_vanilla\", \"roberta_large_sentence\"]:\n",
    "        path = os.path.join(embedding_dir, f\"{split}_{model_name}.npz\")\n",
    "        simcse = False\n",
    "    else:\n",
    "        path = os.path.join(embedding_dir, f\"{split}_simcse_True_{model_name}.npz\")\n",
    "        simcse = True\n",
    "\n",
    "    # create testing embeddings:\n",
    "    embedding_path = path\n",
    "    # data_path = os.path.join(f\"./datasets/TextClassification/{dataset}\", f\"{split}.{suffix}\")\n",
    "    if not os.path.exists(embedding_path):\n",
    "        logger.info(f\"generating train/test embeddings using {model_name} from kermit\")\n",
    "        embedding_list, label_list = unpickled, [0,1,2,4]\n",
    "        label_list = np.array(label_list)\n",
    "        embedding_list = np.array(embedding_list)\n",
    "        logger.info(f\"embedding size: {embedding_list.shape}, label shape: {label_list.shape}\")\n",
    "        logger.info(f\"embeddings saved at {embedding_path}\")\n",
    "        np.savez(embedding_path, embedding_list=embedding_list, label_list=label_list)\n",
    "    else:\n",
    "        logger.info(f\"embeddings already exists at {embedding_path}\")\n",
    "    return path\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding class anchor sentences...\n",
      "generating prompt embeddings using agnews from ./agnews/label_names.txt, template: The news is about <mask>.\n",
      "embedding path = ./agnews/embeddings\\prompt_0_agnews.npz\n",
      "prompt exampe: The news is about politics.\n",
      "prompt exampe: The news is about sports.\n",
      "prompt exampe: The news is about business.\n",
      "prompt exampe: The news is about technology.\n",
      "embedding shape: (4, 4000)\n",
      "generating prompt embeddings using agnews from ./agnews/label_names.txt, template: The news is related to <mask>.\n",
      "embedding path = ./agnews/embeddings\\prompt_1_agnews.npz\n",
      "prompt exampe: The news is related to politics.\n",
      "prompt exampe: The news is related to sports.\n",
      "prompt exampe: The news is related to business.\n",
      "prompt exampe: The news is related to technology.\n",
      "embedding shape: (4, 4000)\n",
      "generating prompt embeddings using agnews from ./agnews/label_names.txt, template: <mask> is the topic of the news.\n",
      "embedding path = ./agnews/embeddings\\prompt_2_agnews.npz\n",
      "prompt exampe: politics is the topic of the news.\n",
      "prompt exampe: sports is the topic of the news.\n",
      "prompt exampe: business is the topic of the news.\n",
      "prompt exampe: technology is the topic of the news.\n",
      "embedding shape: (4, 4000)\n",
      "generating prompt embeddings using agnews from ./agnews/label_names.txt, template: This week's news is about <mask>.\n",
      "embedding path = ./agnews/embeddings\\prompt_3_agnews.npz\n",
      "prompt exampe: This week's news is about politics.\n",
      "prompt exampe: This week's news is about sports.\n",
      "prompt exampe: This week's news is about business.\n",
      "prompt exampe: This week's news is about technology.\n",
      "embedding shape: (4, 4000)\n",
      "generating prompt embeddings using agnews from ./agnews/label_names.txt, template: <mask>\n",
      "embedding path = ./agnews/embeddings\\prompt_4_agnews.npz\n",
      "prompt exampe: politics\n",
      "prompt exampe: sports\n",
      "prompt exampe: business\n",
      "prompt exampe: technology\n",
      "embedding shape: (4, 4000)\n"
     ]
    }
   ],
   "source": [
    "encode_label_names(data_train, \"./agnews/label_names.txt\", None,\"Kermit\", \"agnews\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "'./agnews/dataset/embeddings\\\\0.2_simcse_True_Kermit.npz'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_and_save_sentences(data_train, \"\",\",\",None, \"Kermit\", 0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "print(\"test\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
